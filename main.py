# import os
# import sys
# from pathlib import Path
# from typing import List, Dict
#
# from config import config
# from utils import setup_directories, logger, save_excluded_papers
# from searcher import ArxivSearcher
# from processor import PaperProcessor
# from analyzer import PaperAnalyzer
#
#
# class LiteratureProcessor:
#     def __init__(self):
#         self.config = config
#         self.searcher = ArxivSearcher(self.config)
#         self.processor = PaperProcessor(self.config)
#         self.analyzer = PaperAnalyzer(self.config)
#
#     def initialize(self):
#         """åˆå§‹åŒ–é¡¹ç›®"""
#         setup_directories(self.config)
#
#         # æ£€æŸ¥å¿…è¦æ–‡ä»¶
#         if not os.path.exists(self.config.QUESTION_FILE):
#             logger.error(f"é—®é¢˜æ–‡ä»¶ä¸å­˜åœ¨: {self.config.QUESTION_FILE}")
#             logger.error("è¯·ç¡®ä¿question.txtæ–‡ä»¶å­˜åœ¨å¹¶åŒ…å«åˆ†æé—®é¢˜")
#             return False
#
#         # æ£€æŸ¥APIå¯†é’¥
#         if not self.config.DEEPSEEK_API_KEY:
#             logger.error("DeepSeek APIå¯†é’¥æœªé…ç½®")
#             return False
#
#         return True
#
#     def display_menu(self):
#         """æ˜¾ç¤ºä¸»èœå•"""
#         print("\n" + "=" * 60)
#         print("æ–‡çŒ®å¤„ç†ç³»ç»Ÿ")
#         print("=" * 60)
#         print("1. æœç´¢å¹¶å¤„ç†æ–‡çŒ®")
#         print("2. å¤„ç†å·²ä¸‹è½½çš„æ–‡çŒ®")
#         print("3. é‡æ–°åˆ†æå·²å¤„ç†çš„æ–‡çŒ®")
#         print("4. æŸ¥çœ‹é…ç½®")
#         print("5. æŸ¥çœ‹è®ºæ–‡ç›®å½•ç»“æ„")
#         print("6. é€€å‡º")
#         print("=" * 60)
#
#         choice = input("è¯·é€‰æ‹©æ“ä½œ (1-6): ").strip()
#         return choice
#
#     def show_config(self):
#         """æ˜¾ç¤ºå½“å‰é…ç½®"""
#         print("\nå½“å‰é…ç½®:")
#         print(f"æœç´¢æ¨¡å‹: {self.config.SEARCH_MODEL}")
#         print(f"æ–‡æœ¬åˆ†ææ¨¡å‹: {self.config.TEXT_MODEL}")
#         print(f"å›¾åƒåˆ†ææ¨¡å‹: {self.config.IMAGE_MODEL}")
#         print(f"æœ€å¤§æœç´¢ç»“æœ: {self.config.MAX_RESULTS}")
#         print(f"æœ€å¤§é€‰æ‹©æ•°é‡: {self.config.MAX_SELECTED}")
#         print(f"æ•°æ®ç›®å½•: {self.config.DATA_DIR}")
#         print(f"é—®é¢˜æ–‡ä»¶: {self.config.QUESTION_FILE}")
#         print(f"æ’é™¤æ–‡ä»¶: {self.config.EXCLUDE_CSV}")
#         print(f"MinerU condaç¯å¢ƒ: {self.config.MINERU_CONDA_ENV}")
#         print(f"Arxiv condaç¯å¢ƒ: {self.config.ARXIV_CONDA_ENV}")
#
#     def show_paper_structure(self):
#         """æ˜¾ç¤ºè®ºæ–‡ç›®å½•ç»“æ„"""
#         structure = self.processor.get_paper_directory_structure()
#
#         if not structure:
#             print("\næš‚æ— å·²å¤„ç†çš„è®ºæ–‡")
#             return
#
#         print(f"\nå·²å¤„ç†çš„è®ºæ–‡ç›®å½•ç»“æ„ (å…± {len(structure)} ç¯‡):")
#         print("=" * 80)
#
#         for paper_name, subdirs in structure.items():
#             print(f"\nğŸ“ {paper_name}")
#             for subdir in subdirs:
#                 if subdir == 'pdf':
#                     print(f"   â”œâ”€â”€ ğŸ“„ {subdir}/ (PDFæ–‡ä»¶)")
#                 elif subdir == 'MinerU_process':
#                     print(f"   â”œâ”€â”€ ğŸ“ {subdir}/ (è½¬æ¢ç»“æœ)")
#                 elif subdir == 'result':
#                     print(f"   â””â”€â”€ ğŸ“Š {subdir}/ (åˆ†æç»“æœ)")
#
#     def search_and_process(self):
#         """æœç´¢å¹¶å¤„ç†æ–‡çŒ®çš„å®Œæ•´æµç¨‹"""
#         # 1. è·å–ç”¨æˆ·æŸ¥è¯¢
#         query = input("\nè¯·è¾“å…¥æœç´¢å…³é”®è¯æˆ–æè¿°: ").strip()
#         if not query:
#             logger.warning("æœç´¢å…³é”®è¯ä¸èƒ½ä¸ºç©º")
#             return
#
#         # 2. æœç´¢æ–‡çŒ®
#         logger.info("å¼€å§‹æœç´¢æ–‡çŒ®...")
#         papers = self.searcher.search_and_select(query)
#
#         if not papers:
#             logger.warning("æœªæ‰¾åˆ°åˆé€‚çš„æ–‡çŒ®")
#             return
#
#         # 3. å±•ç¤ºæœç´¢ç»“æœ
#         self.searcher.display_papers(papers)
#
#         # 4. ç”¨æˆ·ç¡®è®¤
#         confirm = input(f"\næ˜¯å¦å¤„ç†è¿™ {len(papers)} ç¯‡æ–‡çŒ®? (y/n): ").strip().lower()
#         if confirm != 'y':
#             logger.info("ç”¨æˆ·å–æ¶ˆæ“ä½œ")
#             return
#
#         # 5. å¤„ç†æ–‡çŒ®
#         logger.info("å¼€å§‹å¤„ç†æ–‡çŒ®...")
#         processed_papers = self.processor.process_papers(papers)
#
#         if not processed_papers:
#             logger.warning("æ²¡æœ‰æˆåŠŸå¤„ç†çš„æ–‡çŒ®")
#             return
#
#         # 6. åˆ†ææ–‡çŒ®
#         logger.info("å¼€å§‹åˆ†ææ–‡çŒ®...")
#         successful_papers = [p for p in processed_papers if p['success']]
#
#         if successful_papers:
#             analysis_results = self.analyzer.analyze_papers(successful_papers)
#         else:
#             analysis_results = []
#
#         # 7. æ›´æ–°æ’é™¤åˆ—è¡¨
#         processed_titles = [paper.get('title', '') for paper in papers]
#         current_excluded = self.searcher.excluded_papers
#         updated_excluded = list(set(current_excluded + processed_titles))
#         save_excluded_papers(
#             self.config.EXCLUDE_CSV,
#             self.config.EXCLUDE_COLUMN,
#             updated_excluded
#         )
#
#         # 8. æ˜¾ç¤ºç»“æœ
#         print(f"\nå¤„ç†å®Œæˆ!")
#         print(f"æˆåŠŸå¤„ç†: {len(successful_papers)} ç¯‡æ–‡çŒ®")
#         print(f"åˆ†æå®Œæˆ: {len(analysis_results)} ç¯‡æ–‡çŒ®")
#         print(f"ç»“æœä¿å­˜åœ¨: {self.config.DATA_DIR}")
#
#     def process_existing(self):
#         """å¤„ç†å·²ä¸‹è½½çš„æ–‡çŒ®"""
#         # æ£€æŸ¥dataç›®å½•ä¸‹æ˜¯å¦æœ‰å·²å­˜åœ¨çš„è®ºæ–‡ç›®å½•
#         if not os.path.exists(self.config.DATA_DIR):
#             logger.warning("æ•°æ®ç›®å½•ä¸å­˜åœ¨")
#             return
#
#         # æŸ¥æ‰¾åŒ…å«PDFçš„è®ºæ–‡ç›®å½•
#         existing_papers = []
#         for item in os.listdir(self.config.DATA_DIR):
#             item_path = os.path.join(self.config.DATA_DIR, item)
#             if os.path.isdir(item_path):
#                 pdf_dir = os.path.join(item_path, 'pdf')
#                 if os.path.exists(pdf_dir):
#                     pdf_files = list(Path(pdf_dir).glob("*.pdf"))
#                     if pdf_files:
#                         # æ£€æŸ¥æ˜¯å¦å·²ç»å¤„ç†è¿‡
#                         mineru_dir = os.path.join(item_path, 'MinerU_process')
#                         if not os.path.exists(mineru_dir) or not os.listdir(mineru_dir):
#                             existing_papers.append({
#                                 'paper_dir': item_path,
#                                 'pdf_path': str(pdf_files[0]),
#                                 'paper_name': item
#                             })
#
#         if not existing_papers:
#             logger.warning("æœªæ‰¾åˆ°éœ€è¦å¤„ç†çš„PDFæ–‡ä»¶")
#             return
#
#         print(f"\næ‰¾åˆ° {len(existing_papers)} ä¸ªæœªå¤„ç†çš„è®ºæ–‡")
#         for i, paper in enumerate(existing_papers, 1):
#             print(f"{i}. {paper['paper_name']}")
#
#         confirm = input(f"\næ˜¯å¦å¤„ç†è¿™ {len(existing_papers)} ç¯‡æ–‡çŒ®? (y/n): ").strip().lower()
#         if confirm != 'y':
#             logger.info("ç”¨æˆ·å–æ¶ˆæ“ä½œ")
#             return
#
#         # å¤„ç†ç°æœ‰è®ºæ–‡
#         processed_papers = []
#         for paper_info in existing_papers:
#             try:
#                 # ä½¿ç”¨ç°æœ‰çš„PDFæ–‡ä»¶è¿›è¡Œè½¬æ¢
#                 mineru_path = self.processor.convert_pdf_to_markdown(
#                     paper_info['pdf_path'],
#                     paper_info['paper_dir']
#                 )
#
#                 if mineru_path:
#                     # æ„é€ å¤„ç†ç»“æœ
#                     result = {
#                         "paper_id": paper_info['paper_name'],
#                         "title": paper_info['paper_name'],
#                         "authors": [],
#                         "published": "",
#                         "success": True,
#                         "paper_dir": paper_info['paper_dir'],
#                         "pdf_path": paper_info['pdf_path'],
#                         "mineru_path": mineru_path,
#                         "main_md_file": self.processor._find_main_markdown_file(mineru_path),
#                         "result_dir": os.path.join(paper_info['paper_dir'], 'result')
#                     }
#
#                     # åˆ†æå›¾ç‰‡
#                     image_analysis_results = self.processor.batch_analyze_images(paper_info['paper_dir'])
#                     if image_analysis_results:
#                         self.processor.save_image_analysis_results(paper_info['paper_dir'], image_analysis_results)
#                         result['image_analysis_completed'] = True
#                         result['total_images_analyzed'] = len(image_analysis_results)
#
#                     processed_papers.append(result)
#                     logger.info(f"å¤„ç†å®Œæˆ: {paper_info['paper_name']}")
#                 else:
#                     logger.error(f"è½¬æ¢å¤±è´¥: {paper_info['paper_name']}")
#
#             except Exception as e:
#                 logger.error(f"å¤„ç† {paper_info['paper_name']} æ—¶å‡ºé”™: {e}")
#
#         if processed_papers:
#             logger.info("å¼€å§‹åˆ†ææ–‡çŒ®...")
#             analysis_results = self.analyzer.analyze_papers(processed_papers)
#             print(f"å¤„ç†å®Œæˆ: {len(analysis_results)} ç¯‡æ–‡çŒ®")
#
#     def reanalyze_existing(self):
#         """é‡æ–°åˆ†æå·²å¤„ç†çš„æ–‡çŒ®"""
#         # æŸ¥æ‰¾å·²å¤„ç†çš„è®ºæ–‡
#         if not os.path.exists(self.config.DATA_DIR):
#             logger.warning("æ•°æ®ç›®å½•ä¸å­˜åœ¨")
#             return
#
#         processed_papers = []
#         for item in os.listdir(self.config.DATA_DIR):
#             item_path = os.path.join(self.config.DATA_DIR, item)
#             if os.path.isdir(item_path):
#                 mineru_dir = os.path.join(item_path, 'MinerU_process')
#                 result_dir = os.path.join(item_path, 'result')
#
#                 # æ£€æŸ¥æ˜¯å¦æœ‰MinerUå¤„ç†ç»“æœ
#                 if os.path.exists(mineru_dir):
#                     main_md = self.processor._find_main_markdown_file(mineru_dir)
#                     if main_md:
#                         result = {
#                             "paper_id": item,
#                             "title": item,
#                             "authors": [],
#                             "published": "",
#                             "success": True,
#                             "paper_dir": item_path,
#                             "pdf_path": "",
#                             "mineru_path": mineru_dir,
#                             "main_md_file": main_md,
#                             "result_dir": result_dir
#                         }
#                         processed_papers.append(result)
#
#         if not processed_papers:
#             logger.warning("æœªæ‰¾åˆ°å·²å¤„ç†çš„æ–‡çŒ®")
#             return
#
#         print(f"\næ‰¾åˆ° {len(processed_papers)} ä¸ªå·²å¤„ç†çš„æ–‡çŒ®")
#         for i, paper in enumerate(processed_papers, 1):
#             print(f"{i}. {paper['paper_id']}")
#
#         confirm = input(f"\næ˜¯å¦é‡æ–°åˆ†æè¿™ {len(processed_papers)} ç¯‡æ–‡çŒ®? (y/n): ").strip().lower()
#         if confirm != 'y':
#             logger.info("ç”¨æˆ·å–æ¶ˆæ“ä½œ")
#             return
#
#         logger.info("å¼€å§‹é‡æ–°åˆ†ææ–‡çŒ®...")
#         analysis_results = self.analyzer.analyze_papers(processed_papers)
#         print(f"é‡æ–°åˆ†æå®Œæˆ: {len(analysis_results)} ç¯‡æ–‡çŒ®")
#
#     def run(self):
#         """è¿è¡Œä¸»ç¨‹åº"""
#         if not self.initialize():
#             logger.error("åˆå§‹åŒ–å¤±è´¥")
#             return
#
#         logger.info("æ–‡çŒ®å¤„ç†ç³»ç»Ÿå·²å¯åŠ¨")
#
#         while True:
#             choice = self.display_menu()
#
#             if choice == '1':
#                 self.search_and_process()
#             elif choice == '2':
#                 self.process_existing()
#             elif choice == '3':
#                 self.reanalyze_existing()
#             elif choice == '4':
#                 self.show_config()
#             elif choice == '5':
#                 self.show_paper_structure()
#             elif choice == '6':
#                 logger.info("é€€å‡ºç³»ç»Ÿ")
#                 break
#             else:
#                 print("æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")
#
#             input("\næŒ‰Enteré”®ç»§ç»­...")
#
#
# if __name__ == "__main__":
#     processor = LiteratureProcessor()
#     processor.run()


import os
import sys
from pathlib import Path
from typing import List, Dict

from config import config
from utils import setup_directories, logger, save_excluded_papers
from searcher import ArxivSearcher
from processor import PaperProcessor
from analyzer import PaperAnalyzer


class LiteratureProcessor:
    def __init__(self):
        self.config = config
        self.searcher = ArxivSearcher(self.config)
        self.processor = PaperProcessor(self.config)
        self.analyzer = PaperAnalyzer(self.config)

    def initialize(self):
        """åˆå§‹åŒ–é¡¹ç›®"""
        setup_directories(self.config)

        # æ£€æŸ¥å¿…è¦æ–‡ä»¶
        if not os.path.exists(self.config.QUESTION_FILE):
            logger.error(f"é—®é¢˜æ–‡ä»¶ä¸å­˜åœ¨: {self.config.QUESTION_FILE}")
            logger.error("è¯·ç¡®ä¿question.txtæ–‡ä»¶å­˜åœ¨å¹¶åŒ…å«åˆ†æé—®é¢˜")
            return False

        # æ£€æŸ¥APIå¯†é’¥
        if not self.config.DEEPSEEK_API_KEY:
            logger.error("DeepSeek APIå¯†é’¥æœªé…ç½®")
            return False

        return True

    def display_menu(self):
        """æ˜¾ç¤ºä¸»èœå•"""
        print("\n" + "=" * 60)
        print("æ–‡çŒ®å¤„ç†ç³»ç»Ÿ")
        print("=" * 60)
        print("1. æœç´¢å¹¶é€‰æ‹©ä¸‹è½½æ–‡çŒ®")
        print("2. å¤„ç†å·²ä¸‹è½½çš„æ–‡çŒ®")
        print("3. é‡æ–°åˆ†æå·²å¤„ç†çš„æ–‡çŒ®")
        print("4. æŸ¥çœ‹é…ç½®")
        print("5. æŸ¥çœ‹è®ºæ–‡ç›®å½•ç»“æ„")
        print("6. é€€å‡º")
        print("=" * 60)

        choice = input("è¯·é€‰æ‹©æ“ä½œ (1-6): ").strip()
        return choice

    def show_config(self):
        """æ˜¾ç¤ºå½“å‰é…ç½®"""
        print("\nå½“å‰é…ç½®:")
        print(f"æœç´¢æ¨¡å‹: {self.config.SEARCH_MODEL}")
        print(f"æ–‡æœ¬åˆ†ææ¨¡å‹: {self.config.TEXT_MODEL}")
        print(f"å›¾åƒåˆ†ææ¨¡å‹: {self.config.IMAGE_MODEL}")
        print(f"æœ€å¤§æœç´¢ç»“æœ: {self.config.MAX_RESULTS}")
        print(f"æœ€å¤§é€‰æ‹©æ•°é‡: {self.config.MAX_SELECTED}")
        print(f"æ•°æ®ç›®å½•: {self.config.DATA_DIR}")
        print(f"é—®é¢˜æ–‡ä»¶: {self.config.QUESTION_FILE}")
        print(f"æ’é™¤æ–‡ä»¶: {self.config.EXCLUDE_CSV}")
        print(f"MinerU condaç¯å¢ƒ: {self.config.MINERU_CONDA_ENV}")
        print(f"Arxiv condaç¯å¢ƒ: {self.config.ARXIV_CONDA_ENV}")

    def show_paper_structure(self):
        """æ˜¾ç¤ºè®ºæ–‡ç›®å½•ç»“æ„"""
        structure = self.processor.get_paper_directory_structure()

        if not structure:
            print("\næš‚æ— å·²å¤„ç†çš„è®ºæ–‡")
            return

        print(f"\nå·²å¤„ç†çš„è®ºæ–‡ç›®å½•ç»“æ„ (å…± {len(structure)} ç¯‡):")
        print("=" * 80)

        for paper_name, subdirs in structure.items():
            print(f"\nğŸ“ {paper_name}")
            for subdir in subdirs:
                if subdir == 'pdf':
                    print(f"   â”œâ”€â”€ ğŸ“„ {subdir}/ (PDFæ–‡ä»¶)")
                elif subdir == 'MinerU_process':
                    print(f"   â”œâ”€â”€ ğŸ“ {subdir}/ (è½¬æ¢ç»“æœ)")
                elif subdir == 'result':
                    print(f"   â””â”€â”€ ğŸ“Š {subdir}/ (åˆ†æç»“æœ)")

    def get_user_selection(self, papers: List[Dict]) -> List[Dict]:
        """è®©ç”¨æˆ·é€‰æ‹©è¦ä¸‹è½½çš„è®ºæ–‡"""
        if not papers:
            return []

        print("\nè¯·é€‰æ‹©è¦ä¸‹è½½çš„è®ºæ–‡ï¼ˆå¯ä»¥å¤šé€‰ï¼‰:")
        print("è¾“å…¥æ ¼å¼ç¤ºä¾‹:")
        print("  å•ä¸ª: 3")
        print("  å¤šä¸ª: 1,3,5")
        print("  èŒƒå›´: 1-5")
        print("  ç»„åˆ: 1,3-5,8")
        print("  å…¨éƒ¨: all")
        print("  å–æ¶ˆ: cancel")

        while True:
            user_input = input("\nè¯·è¾“å…¥é€‰æ‹©: ").strip().lower()

            if user_input == 'cancel':
                return []

            if user_input == 'all':
                return papers

            try:
                selected_indices = self._parse_selection(user_input, len(papers))
                if selected_indices:
                    selected_papers = [papers[i - 1] for i in selected_indices]  # è½¬æ¢ä¸º0-basedç´¢å¼•

                    # æ˜¾ç¤ºé€‰æ‹©çš„è®ºæ–‡
                    print(f"\næ‚¨é€‰æ‹©äº†ä»¥ä¸‹ {len(selected_papers)} ç¯‡è®ºæ–‡:")
                    for i, paper in enumerate(selected_papers, 1):
                        title = paper.get('title', 'Unknown Title')[:60]
                        print(f"{i}. {title}...")

                    confirm = input(f"\nç¡®è®¤ä¸‹è½½è¿™ {len(selected_papers)} ç¯‡è®ºæ–‡? (y/n): ").strip().lower()
                    if confirm == 'y':
                        return selected_papers
                    else:
                        print("è¯·é‡æ–°é€‰æ‹©:")
                        continue
                else:
                    print("æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")
                    continue
            except Exception as e:
                print(f"è¾“å…¥æ ¼å¼é”™è¯¯: {e}")
                continue

    def _parse_selection(self, user_input: str, max_count: int) -> List[int]:
        """è§£æç”¨æˆ·é€‰æ‹©çš„ç¼–å·"""
        indices = set()

        # æŒ‰é€—å·åˆ†å‰²
        parts = [part.strip() for part in user_input.split(',')]

        for part in parts:
            if '-' in part:
                # å¤„ç†èŒƒå›´ (å¦‚ 1-5)
                try:
                    start, end = map(int, part.split('-'))
                    if 1 <= start <= max_count and 1 <= end <= max_count and start <= end:
                        indices.update(range(start, end + 1))
                    else:
                        raise ValueError(f"èŒƒå›´ {part} è¶…å‡ºæœ‰æ•ˆèŒƒå›´ 1-{max_count}")
                except ValueError as e:
                    raise ValueError(f"æ— æ•ˆèŒƒå›´æ ¼å¼: {part}")
            else:
                # å¤„ç†å•ä¸ªæ•°å­—
                try:
                    num = int(part)
                    if 1 <= num <= max_count:
                        indices.add(num)
                    else:
                        raise ValueError(f"ç¼–å· {num} è¶…å‡ºæœ‰æ•ˆèŒƒå›´ 1-{max_count}")
                except ValueError:
                    raise ValueError(f"æ— æ•ˆç¼–å·: {part}")

        return sorted(list(indices))

    def search_and_process(self):
        """æœç´¢å¹¶é€‰æ‹©ä¸‹è½½æ–‡çŒ®çš„å®Œæ•´æµç¨‹"""
        # 1. è·å–ç”¨æˆ·æŸ¥è¯¢
        query = input("\nè¯·è¾“å…¥æœç´¢å…³é”®è¯æˆ–æè¿°: ").strip()
        if not query:
            logger.warning("æœç´¢å…³é”®è¯ä¸èƒ½ä¸ºç©º")
            return

        # 2. æœç´¢æ–‡çŒ®
        logger.info("å¼€å§‹æœç´¢æ–‡çŒ®...")
        papers = self.searcher.search_and_select(query)

        if not papers:
            logger.warning("æœªæ‰¾åˆ°åˆé€‚çš„æ–‡çŒ®")
            return

        # 3. å±•ç¤ºæœç´¢ç»“æœ
        self.searcher.display_papers(papers)

        # 4. ç”¨æˆ·é€‰æ‹©è¦ä¸‹è½½çš„è®ºæ–‡
        selected_papers = self.get_user_selection(papers)

        if not selected_papers:
            logger.info("ç”¨æˆ·å–æ¶ˆæ“ä½œæˆ–æœªé€‰æ‹©è®ºæ–‡")
            return

        # 5. å¤„ç†é€‰ä¸­çš„æ–‡çŒ®
        logger.info(f"å¼€å§‹å¤„ç†é€‰ä¸­çš„ {len(selected_papers)} ç¯‡æ–‡çŒ®...")
        processed_papers = self.processor.process_papers(selected_papers)

        if not processed_papers:
            logger.warning("æ²¡æœ‰æˆåŠŸå¤„ç†çš„æ–‡çŒ®")
            return

        # 6. åˆ†ææ–‡çŒ®
        logger.info("å¼€å§‹åˆ†ææ–‡çŒ®...")
        successful_papers = [p for p in processed_papers if p['success']]

        if successful_papers:
            analysis_results = self.analyzer.analyze_papers(successful_papers)
        else:
            analysis_results = []

        # 7. æ›´æ–°æ’é™¤åˆ—è¡¨ï¼ˆåªæ’é™¤å·²å¤„ç†çš„è®ºæ–‡ï¼‰
        processed_titles = [paper.get('title', '') for paper in selected_papers]
        current_excluded = self.searcher.excluded_papers
        updated_excluded = list(set(current_excluded + processed_titles))
        save_excluded_papers(
            self.config.EXCLUDE_CSV,
            self.config.EXCLUDE_COLUMN,
            updated_excluded
        )

        # 8. æ˜¾ç¤ºç»“æœ
        print(f"\nå¤„ç†å®Œæˆ!")
        print(f"é€‰æ‹©ä¸‹è½½: {len(selected_papers)} ç¯‡æ–‡çŒ®")
        print(f"æˆåŠŸå¤„ç†: {len(successful_papers)} ç¯‡æ–‡çŒ®")
        print(f"åˆ†æå®Œæˆ: {len(analysis_results)} ç¯‡æ–‡çŒ®")
        print(f"ç»“æœä¿å­˜åœ¨: {self.config.DATA_DIR}")

        # 9. æ˜¾ç¤ºæœªä¸‹è½½çš„è®ºæ–‡
        unselected_count = len(papers) - len(selected_papers)
        if unselected_count > 0:
            print(f"æœªä¸‹è½½: {unselected_count} ç¯‡æ–‡çŒ®")
            save_unselected = input("æ˜¯å¦ä¿å­˜æœªä¸‹è½½çš„è®ºæ–‡åˆ—è¡¨? (y/n): ").strip().lower()
            if save_unselected == 'y':
                self._save_unselected_papers(papers, selected_papers)

    def _save_unselected_papers(self, all_papers: List[Dict], selected_papers: List[Dict]):
        """ä¿å­˜æœªé€‰æ‹©çš„è®ºæ–‡åˆ—è¡¨"""
        selected_titles = {paper.get('title', '') for paper in selected_papers}
        unselected_papers = [paper for paper in all_papers if paper.get('title', '') not in selected_titles]

        unselected_file = os.path.join(self.config.DATA_DIR, 'unselected_papers.txt')

        try:
            with open(unselected_file, 'w', encoding='utf-8') as f:
                f.write("æœªä¸‹è½½çš„è®ºæ–‡åˆ—è¡¨\n")
                f.write("=" * 50 + "\n\n")

                for i, paper in enumerate(unselected_papers, 1):
                    f.write(f"{i}. {paper.get('title', 'Unknown Title')}\n")
                    f.write(f"   ä½œè€…: {', '.join(paper.get('authors', []))}\n")
                    f.write(f"   å‘è¡¨æ—¶é—´: {paper.get('published', 'Unknown')}\n")
                    f.write(f"   é“¾æ¥: {paper.get('entry_id', '')}\n")
                    f.write(f"   æ‘˜è¦: {paper.get('summary', '')[:200]}...\n")
                    f.write("-" * 50 + "\n")

            print(f"æœªä¸‹è½½è®ºæ–‡åˆ—è¡¨å·²ä¿å­˜åˆ°: {unselected_file}")

        except Exception as e:
            logger.error(f"ä¿å­˜æœªä¸‹è½½è®ºæ–‡åˆ—è¡¨å¤±è´¥: {e}")

    def process_existing(self):
        """å¤„ç†å·²ä¸‹è½½çš„æ–‡çŒ®"""
        # æ£€æŸ¥dataç›®å½•ä¸‹æ˜¯å¦æœ‰å·²å­˜åœ¨çš„è®ºæ–‡ç›®å½•
        if not os.path.exists(self.config.DATA_DIR):
            logger.warning("æ•°æ®ç›®å½•ä¸å­˜åœ¨")
            return

        # æŸ¥æ‰¾åŒ…å«PDFçš„è®ºæ–‡ç›®å½•
        existing_papers = []
        for item in os.listdir(self.config.DATA_DIR):
            item_path = os.path.join(self.config.DATA_DIR, item)
            if os.path.isdir(item_path):
                pdf_dir = os.path.join(item_path, 'pdf')
                if os.path.exists(pdf_dir):
                    pdf_files = list(Path(pdf_dir).glob("*.pdf"))
                    if pdf_files:
                        # æ£€æŸ¥æ˜¯å¦å·²ç»å¤„ç†è¿‡
                        mineru_dir = os.path.join(item_path, 'MinerU_process')
                        if not os.path.exists(mineru_dir) or not os.listdir(mineru_dir):
                            existing_papers.append({
                                'paper_dir': item_path,
                                'pdf_path': str(pdf_files[0]),
                                'paper_name': item
                            })

        if not existing_papers:
            logger.warning("æœªæ‰¾åˆ°éœ€è¦å¤„ç†çš„PDFæ–‡ä»¶")
            return

        print(f"\næ‰¾åˆ° {len(existing_papers)} ä¸ªæœªå¤„ç†çš„è®ºæ–‡:")
        for i, paper in enumerate(existing_papers, 1):
            print(f"{i}. {paper['paper_name']}")

        # è®©ç”¨æˆ·é€‰æ‹©è¦å¤„ç†çš„è®ºæ–‡
        selected_papers = self._select_existing_papers(existing_papers)

        if not selected_papers:
            logger.info("ç”¨æˆ·å–æ¶ˆæ“ä½œæˆ–æœªé€‰æ‹©è®ºæ–‡")
            return

        # å¤„ç†é€‰ä¸­çš„è®ºæ–‡
        processed_papers = []
        for paper_info in selected_papers:
            try:
                # ä½¿ç”¨ç°æœ‰çš„PDFæ–‡ä»¶è¿›è¡Œè½¬æ¢
                mineru_path = self.processor.convert_pdf_to_markdown(
                    paper_info['pdf_path'],
                    paper_info['paper_dir']
                )

                if mineru_path:
                    # æ„é€ å¤„ç†ç»“æœ
                    result = {
                        "paper_id": paper_info['paper_name'],
                        "title": paper_info['paper_name'],
                        "authors": [],
                        "published": "",
                        "success": True,
                        "paper_dir": paper_info['paper_dir'],
                        "pdf_path": paper_info['pdf_path'],
                        "mineru_path": mineru_path,
                        "main_md_file": self.processor._find_main_markdown_file(mineru_path),
                        "result_dir": os.path.join(paper_info['paper_dir'], 'result')
                    }

                    # åˆ†æå›¾ç‰‡
                    image_analysis_results = self.processor.batch_analyze_images(paper_info['paper_dir'])
                    if image_analysis_results:
                        self.processor.save_image_analysis_results(paper_info['paper_dir'], image_analysis_results)
                        result['image_analysis_completed'] = True
                        result['total_images_analyzed'] = len(image_analysis_results)

                    processed_papers.append(result)
                    logger.info(f"å¤„ç†å®Œæˆ: {paper_info['paper_name']}")
                else:
                    logger.error(f"è½¬æ¢å¤±è´¥: {paper_info['paper_name']}")

            except Exception as e:
                logger.error(f"å¤„ç† {paper_info['paper_name']} æ—¶å‡ºé”™: {e}")

        if processed_papers:
            logger.info("å¼€å§‹åˆ†ææ–‡çŒ®...")
            analysis_results = self.analyzer.analyze_papers(processed_papers)
            print(f"å¤„ç†å®Œæˆ: {len(analysis_results)} ç¯‡æ–‡çŒ®")

    def _select_existing_papers(self, existing_papers: List[Dict]) -> List[Dict]:
        """é€‰æ‹©è¦å¤„ç†çš„ç°æœ‰è®ºæ–‡"""
        print("\nè¯·é€‰æ‹©è¦å¤„ç†çš„è®ºæ–‡ï¼ˆè¾“å…¥æ ¼å¼åŒæœç´¢ç»“æœé€‰æ‹©ï¼‰:")

        while True:
            user_input = input("è¯·è¾“å…¥é€‰æ‹© (æˆ–è¾“å…¥ 'all' å¤„ç†å…¨éƒ¨, 'cancel' å–æ¶ˆ): ").strip().lower()

            if user_input == 'cancel':
                return []

            if user_input == 'all':
                return existing_papers

            try:
                selected_indices = self._parse_selection(user_input, len(existing_papers))
                if selected_indices:
                    selected_papers = [existing_papers[i - 1] for i in selected_indices]

                    print(f"\næ‚¨é€‰æ‹©äº†ä»¥ä¸‹ {len(selected_papers)} ç¯‡è®ºæ–‡:")
                    for i, paper in enumerate(selected_papers, 1):
                        print(f"{i}. {paper['paper_name']}")

                    confirm = input(f"\nç¡®è®¤å¤„ç†è¿™ {len(selected_papers)} ç¯‡è®ºæ–‡? (y/n): ").strip().lower()
                    if confirm == 'y':
                        return selected_papers
                    else:
                        continue
                else:
                    print("æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")
                    continue
            except Exception as e:
                print(f"è¾“å…¥æ ¼å¼é”™è¯¯: {e}")
                continue

    def reanalyze_existing(self):
        """é‡æ–°åˆ†æå·²å¤„ç†çš„æ–‡çŒ®"""
        # æŸ¥æ‰¾å·²å¤„ç†çš„è®ºæ–‡
        if not os.path.exists(self.config.DATA_DIR):
            logger.warning("æ•°æ®ç›®å½•ä¸å­˜åœ¨")
            return

        processed_papers = []
        for item in os.listdir(self.config.DATA_DIR):
            item_path = os.path.join(self.config.DATA_DIR, item)
            if os.path.isdir(item_path):
                mineru_dir = os.path.join(item_path, 'MinerU_process')
                result_dir = os.path.join(item_path, 'result')

                # æ£€æŸ¥æ˜¯å¦æœ‰MinerUå¤„ç†ç»“æœ
                if os.path.exists(mineru_dir):
                    main_md = self.processor._find_main_markdown_file(mineru_dir)
                    if main_md:
                        result = {
                            "paper_id": item,
                            "title": item,
                            "authors": [],
                            "published": "",
                            "success": True,
                            "paper_dir": item_path,
                            "pdf_path": "",
                            "mineru_path": mineru_dir,
                            "main_md_file": main_md,
                            "result_dir": result_dir
                        }
                        processed_papers.append(result)

        if not processed_papers:
            logger.warning("æœªæ‰¾åˆ°å·²å¤„ç†çš„æ–‡çŒ®")
            return

        print(f"\næ‰¾åˆ° {len(processed_papers)} ä¸ªå·²å¤„ç†çš„æ–‡çŒ®:")
        for i, paper in enumerate(processed_papers, 1):
            print(f"{i}. {paper['paper_id']}")

        # è®©ç”¨æˆ·é€‰æ‹©è¦é‡æ–°åˆ†æçš„è®ºæ–‡
        selected_papers = self._select_processed_papers(processed_papers)

        if not selected_papers:
            logger.info("ç”¨æˆ·å–æ¶ˆæ“ä½œæˆ–æœªé€‰æ‹©è®ºæ–‡")
            return

        logger.info(f"å¼€å§‹é‡æ–°åˆ†æé€‰ä¸­çš„ {len(selected_papers)} ç¯‡æ–‡çŒ®...")
        analysis_results = self.analyzer.analyze_papers(selected_papers)
        print(f"é‡æ–°åˆ†æå®Œæˆ: {len(analysis_results)} ç¯‡æ–‡çŒ®")

    def _select_processed_papers(self, processed_papers: List[Dict]) -> List[Dict]:
        """é€‰æ‹©è¦é‡æ–°åˆ†æçš„è®ºæ–‡"""
        print("\nè¯·é€‰æ‹©è¦é‡æ–°åˆ†æçš„è®ºæ–‡:")

        while True:
            user_input = input("è¯·è¾“å…¥é€‰æ‹© (æˆ–è¾“å…¥ 'all' åˆ†æå…¨éƒ¨, 'cancel' å–æ¶ˆ): ").strip().lower()

            if user_input == 'cancel':
                return []

            if user_input == 'all':
                return processed_papers

            try:
                selected_indices = self._parse_selection(user_input, len(processed_papers))
                if selected_indices:
                    selected_papers = [processed_papers[i - 1] for i in selected_indices]

                    print(f"\næ‚¨é€‰æ‹©äº†ä»¥ä¸‹ {len(selected_papers)} ç¯‡è®ºæ–‡:")
                    for i, paper in enumerate(selected_papers, 1):
                        print(f"{i}. {paper['paper_id']}")

                    confirm = input(f"\nç¡®è®¤é‡æ–°åˆ†æè¿™ {len(selected_papers)} ç¯‡è®ºæ–‡? (y/n): ").strip().lower()
                    if confirm == 'y':
                        return selected_papers
                    else:
                        continue
                else:
                    print("æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")
                    continue
            except Exception as e:
                print(f"è¾“å…¥æ ¼å¼é”™è¯¯: {e}")
                continue

    def run(self):
        """è¿è¡Œä¸»ç¨‹åº"""
        if not self.initialize():
            logger.error("åˆå§‹åŒ–å¤±è´¥")
            return

        logger.info("æ–‡çŒ®å¤„ç†ç³»ç»Ÿå·²å¯åŠ¨")

        while True:
            choice = self.display_menu()

            if choice == '1':
                self.search_and_process()
            elif choice == '2':
                self.process_existing()
            elif choice == '3':
                self.reanalyze_existing()
            elif choice == '4':
                self.show_config()
            elif choice == '5':
                self.show_paper_structure()
            elif choice == '6':
                logger.info("é€€å‡ºç³»ç»Ÿ")
                break
            else:
                print("æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")

            input("\næŒ‰Enteré”®ç»§ç»­...")


if __name__ == "__main__":
    processor = LiteratureProcessor()
    processor.run()
